[2022-06-21 13:55:07,062] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: CSV_TO_DS.create_schema_and_tables_logs manual__2022-06-21T13:55:04.876444+00:00 [queued]>
[2022-06-21 13:55:07,073] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: CSV_TO_DS.create_schema_and_tables_logs manual__2022-06-21T13:55:04.876444+00:00 [queued]>
[2022-06-21 13:55:07,073] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 13:55:07,073] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-06-21 13:55:07,073] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 13:55:07,082] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): create_schema_and_tables_logs> on 2022-06-21 13:55:04.876444+00:00
[2022-06-21 13:55:07,086] {standard_task_runner.py:52} INFO - Started process 317 to run task
[2022-06-21 13:55:07,089] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'CSV_TO_DS', 'create_schema_and_tables_logs', 'manual__2022-06-21T13:55:04.876444+00:00', '--job-id', '515', '--raw', '--subdir', 'DAGS_FOLDER/csv_to_ds.py', '--cfg-path', '/tmp/tmpiisbrcyd', '--error-file', '/tmp/tmpwenwjtcl']
[2022-06-21 13:55:07,090] {standard_task_runner.py:77} INFO - Job 515: Subtask create_schema_and_tables_logs
[2022-06-21 13:55:07,137] {logging_mixin.py:109} INFO - Running <TaskInstance: CSV_TO_DS.create_schema_and_tables_logs manual__2022-06-21T13:55:04.876444+00:00 [running]> on host c087b85f9f15
[2022-06-21 13:55:07,182] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=CSV_TO_DS
AIRFLOW_CTX_TASK_ID=create_schema_and_tables_logs
AIRFLOW_CTX_EXECUTION_DATE=2022-06-21T13:55:04.876444+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-06-21T13:55:04.876444+00:00
[2022-06-21 13:55:07,189] {base.py:79} INFO - Using connection to: id: postgres. Host: postgres, Port: 5432, Schema: postgres, Login: ***, Password: ***, extra: {}
[2022-06-21 13:55:07,192] {dbapi.py:225} INFO - Running statement: CREATE SCHEMA IF NOT EXISTS logs;
CREATE SCHEMA IF NOT EXISTS dm;
CREATE SEQUENCE IF NOT EXISTS dm.seq_lg_messages INCREMENT 1 START 1;


CREATE TABLE IF NOT EXISTS logs.load_csv_to_ds (
    ID SERIAL PRIMARY KEY,
    TABLE_NAME VARCHAR(30),
    CSV_PATH TEXT,
    TIME_START_LOAD TIMESTAMP DEFAULT CURRENT_TIMESTAMP(0),
    TIME_END_LOAD TIMESTAMP,
    condition TEXT
);


CREATE TABLE IF NOT EXISTS dm.lg_messages ( 	
    record_id INT,
    date_time TIMESTAMP,
    pid TEXT,
    message TEXT,
    message_type TEXT,
    usename TEXT, 
    datname TEXT, 
    client_addr TEXT, 
    application_name TEXT,
    backend_start TEXT
);, parameters: None
[2022-06-21 13:55:07,193] {postgres.py:71} INFO - NOTICE:  schema "logs" already exists, skipping

[2022-06-21 13:55:07,193] {postgres.py:71} INFO - NOTICE:  schema "dm" already exists, skipping

[2022-06-21 13:55:07,193] {postgres.py:71} INFO - NOTICE:  relation "seq_lg_messages" already exists, skipping

[2022-06-21 13:55:07,193] {postgres.py:71} INFO - NOTICE:  relation "load_csv_to_ds" already exists, skipping

[2022-06-21 13:55:07,193] {postgres.py:71} INFO - NOTICE:  relation "lg_messages" already exists, skipping

[2022-06-21 13:55:07,202] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=CSV_TO_DS, task_id=create_schema_and_tables_logs, execution_date=20220621T135504, start_date=20220621T135507, end_date=20220621T135507
[2022-06-21 13:55:07,222] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-06-21 13:55:07,263] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
