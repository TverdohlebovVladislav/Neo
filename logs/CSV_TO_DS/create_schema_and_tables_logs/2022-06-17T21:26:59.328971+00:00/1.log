[2022-06-18 21:27:02,480] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: CSV_TO_DS.create_schema_and_tables_logs scheduled__2022-06-17T21:26:59.328971+00:00 [queued]>
[2022-06-18 21:27:02,487] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: CSV_TO_DS.create_schema_and_tables_logs scheduled__2022-06-17T21:26:59.328971+00:00 [queued]>
[2022-06-18 21:27:02,488] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 21:27:02,488] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-06-18 21:27:02,488] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 21:27:02,496] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): create_schema_and_tables_logs> on 2022-06-17 21:26:59.328971+00:00
[2022-06-18 21:27:02,500] {standard_task_runner.py:52} INFO - Started process 562 to run task
[2022-06-18 21:27:02,502] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'CSV_TO_DS', 'create_schema_and_tables_logs', 'scheduled__2022-06-17T21:26:59.328971+00:00', '--job-id', '306', '--raw', '--subdir', 'DAGS_FOLDER/csv_to_ds.py', '--cfg-path', '/tmp/tmpmhlqcva5', '--error-file', '/tmp/tmpz0ky8etv']
[2022-06-18 21:27:02,503] {standard_task_runner.py:77} INFO - Job 306: Subtask create_schema_and_tables_logs
[2022-06-18 21:27:02,550] {logging_mixin.py:109} INFO - Running <TaskInstance: CSV_TO_DS.create_schema_and_tables_logs scheduled__2022-06-17T21:26:59.328971+00:00 [running]> on host c087b85f9f15
[2022-06-18 21:27:02,603] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=CSV_TO_DS
AIRFLOW_CTX_TASK_ID=create_schema_and_tables_logs
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T21:26:59.328971+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T21:26:59.328971+00:00
[2022-06-18 21:27:02,610] {base.py:79} INFO - Using connection to: id: postgres. Host: postgres, Port: 5432, Schema: postgres, Login: ***, Password: ***, extra: {}
[2022-06-18 21:27:02,613] {dbapi.py:225} INFO - Running statement: CREATE SCHEMA IF NOT EXISTS logs;
CREATE SCHEMA IF NOT EXISTS dm;
CREATE SEQUENCE IF NOT EXISTS dm.seq_lg_messages INCREMENT 1 START 1;


CREATE TABLE IF NOT EXISTS logs.load_csv_to_ds (
    ID SERIAL PRIMARY KEY,
    TABLE_NAME VARCHAR(30),
    CSV_PATH TEXT,
    TIME_START_LOAD TIMESTAMP DEFAULT CURRENT_TIMESTAMP(0),
    TIME_END_LOAD TIMESTAMP,
    condition TEXT
);


CREATE TABLE IF NOT EXISTS dm.lg_messages ( 	
    record_id INT,
    date_time TIMESTAMP,
    pid TEXT,
    message TEXT,
    message_type TEXT,
    usename TEXT, 
    datname TEXT, 
    client_addr TEXT, 
    application_name TEXT,
    backend_start TEXT
);, parameters: None
[2022-06-18 21:27:02,615] {postgres.py:71} INFO - NOTICE:  schema "logs" already exists, skipping

[2022-06-18 21:27:02,615] {postgres.py:71} INFO - NOTICE:  schema "dm" already exists, skipping

[2022-06-18 21:27:02,615] {postgres.py:71} INFO - NOTICE:  relation "seq_lg_messages" already exists, skipping

[2022-06-18 21:27:02,615] {postgres.py:71} INFO - NOTICE:  relation "load_csv_to_ds" already exists, skipping

[2022-06-18 21:27:02,616] {postgres.py:71} INFO - NOTICE:  relation "lg_messages" already exists, skipping

[2022-06-18 21:27:02,624] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=CSV_TO_DS, task_id=create_schema_and_tables_logs, execution_date=20220617T212659, start_date=20220618T212702, end_date=20220618T212702
[2022-06-18 21:27:02,676] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-06-18 21:27:02,735] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
