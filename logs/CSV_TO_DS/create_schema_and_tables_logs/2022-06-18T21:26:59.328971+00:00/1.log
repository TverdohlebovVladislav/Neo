[2022-06-20 07:03:45,100] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: CSV_TO_DS.create_schema_and_tables_logs scheduled__2022-06-18T21:26:59.328971+00:00 [queued]>
[2022-06-20 07:03:45,111] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: CSV_TO_DS.create_schema_and_tables_logs scheduled__2022-06-18T21:26:59.328971+00:00 [queued]>
[2022-06-20 07:03:45,111] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 07:03:45,111] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-06-20 07:03:45,111] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 07:03:45,123] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): create_schema_and_tables_logs> on 2022-06-18 21:26:59.328971+00:00
[2022-06-20 07:03:45,128] {standard_task_runner.py:52} INFO - Started process 76 to run task
[2022-06-20 07:03:45,136] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'CSV_TO_DS', 'create_schema_and_tables_logs', 'scheduled__2022-06-18T21:26:59.328971+00:00', '--job-id', '392', '--raw', '--subdir', 'DAGS_FOLDER/csv_to_ds.py', '--cfg-path', '/tmp/tmp6y5vhk3r', '--error-file', '/tmp/tmpfstuiqpk']
[2022-06-20 07:03:45,137] {standard_task_runner.py:77} INFO - Job 392: Subtask create_schema_and_tables_logs
[2022-06-20 07:03:45,223] {logging_mixin.py:109} INFO - Running <TaskInstance: CSV_TO_DS.create_schema_and_tables_logs scheduled__2022-06-18T21:26:59.328971+00:00 [running]> on host c087b85f9f15
[2022-06-20 07:03:45,317] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=CSV_TO_DS
AIRFLOW_CTX_TASK_ID=create_schema_and_tables_logs
AIRFLOW_CTX_EXECUTION_DATE=2022-06-18T21:26:59.328971+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-18T21:26:59.328971+00:00
[2022-06-20 07:03:45,328] {base.py:79} INFO - Using connection to: id: postgres. Host: postgres, Port: 5432, Schema: postgres, Login: ***, Password: ***, extra: {}
[2022-06-20 07:03:45,331] {dbapi.py:225} INFO - Running statement: CREATE SCHEMA IF NOT EXISTS logs;
CREATE SCHEMA IF NOT EXISTS dm;
CREATE SEQUENCE IF NOT EXISTS dm.seq_lg_messages INCREMENT 1 START 1;


CREATE TABLE IF NOT EXISTS logs.load_csv_to_ds (
    ID SERIAL PRIMARY KEY,
    TABLE_NAME VARCHAR(30),
    CSV_PATH TEXT,
    TIME_START_LOAD TIMESTAMP DEFAULT CURRENT_TIMESTAMP(0),
    TIME_END_LOAD TIMESTAMP,
    condition TEXT
);


CREATE TABLE IF NOT EXISTS dm.lg_messages ( 	
    record_id INT,
    date_time TIMESTAMP,
    pid TEXT,
    message TEXT,
    message_type TEXT,
    usename TEXT, 
    datname TEXT, 
    client_addr TEXT, 
    application_name TEXT,
    backend_start TEXT
);, parameters: None
[2022-06-20 07:03:45,332] {postgres.py:71} INFO - NOTICE:  schema "logs" already exists, skipping

[2022-06-20 07:03:45,333] {postgres.py:71} INFO - NOTICE:  schema "dm" already exists, skipping

[2022-06-20 07:03:45,333] {postgres.py:71} INFO - NOTICE:  relation "seq_lg_messages" already exists, skipping

[2022-06-20 07:03:45,333] {postgres.py:71} INFO - NOTICE:  relation "load_csv_to_ds" already exists, skipping

[2022-06-20 07:03:45,333] {postgres.py:71} INFO - NOTICE:  relation "lg_messages" already exists, skipping

[2022-06-20 07:03:45,343] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=CSV_TO_DS, task_id=create_schema_and_tables_logs, execution_date=20220618T212659, start_date=20220620T070345, end_date=20220620T070345
[2022-06-20 07:03:45,385] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-06-20 07:03:45,425] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
